# ğŸ“¦ ETL/ELT Analytics Engineering Pipeline
End-to-End Retail Analytics Platform using the Medallion Architecture (Bronze â†’ Silver â†’ Gold), DuckDB, PySpark, Airflow, and Power BI

## â­ 1. Overview
This project showcases a full analytics engineering workflow, designed as a take-home challenge to demonstrate:

- Data modeling
- Automation
- Pipeline engineering
- SQL Development
- KPI design
- Dashboard development
- PySpark analytics
- Airflow DAG orchestration

The goal is to simulate a real-world retail analytics pipeline that ingests ERP + CRM sales data, cleans it, models it using Medallion principles, generates KPIs, and feeds a Power BI dashboard.
This project is intentionally built for scalability, clarity, and enterprise-readiness.

## â­ 2. Data Architecture
<img width="893" height="625" alt="Data Architecture" src="https://github.com/user-attachments/assets/073b01e2-881e-4851-936a-e862ff888142" />

## â­ 3. Key Features
### âœ” Medallion Architecture (Bronze â†’ Silver â†’ Gold)
- Bronze: Raw ingestion with DuckDB
- Silver: Cleaned + conformed models
- Gold: Fact & Dim tables with surrogate keys

### âœ” PySpark Analytics Module
- Customer segmentation (High / Medium / Low) based on spending percentiles.

### âœ” Airflow DAG Overview
Tasks:
- ingest_bronze
- validate_data
- run_silver
- run_gold
- run_kpi
- run_pyspark_segmentation
- export_for_powerbi
DAG reflects a real Medallion workflow.

### âœ” Power BI Dashboard
- Executive Sales Overview
- Customer Insights
- Product & Category Performance

## â­ 4. Tech Stack
| Layer            | Tools / Technologies                         |
|------------------|-----------------------------------------------|
| Storage          | DuckDB                                        |
| Transformation   | SQL (Bronze, Silver, Gold)        |
| Processing       | PySpark                                       |
| Orchestration    | Apache Airflow                                |
| Visualization    | Power BI                                      |
| Programming      | Python, SQL, PySpark                                         |
| Data Modeling    | Medallion Architecture + Star Schema (SKs)    |

## â­ 5. Folder Structure
```
â”œâ”€â”€ airflow_dags/
â”‚   â””â”€â”€ retail_pipeline_dag.py
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”œâ”€â”€ validation.py
â”‚   â”œâ”€â”€ run_silver.py
â”‚   â”œâ”€â”€ run_gold.py
â”‚   â””â”€â”€ run_kpi.py
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ customer_segmentation.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ gold/
â”‚   â””â”€â”€ kpi/
â”œâ”€â”€ exports/
â”‚   â”œâ”€â”€ fact_sales.csv
â”‚   â”œâ”€â”€ dim_customer.csv
â”‚   â””â”€â”€ dim_product.csv
â””â”€â”€ README.md
```

## â­ 6. PySpark Module
File: spark/customer_segmentation.py
Implements:
- Load fact + dim datasets
- Join and aggregate customer revenue
- Compute percentiles
- Classify customers into:
  - High Value
  - Medium Value
  - Low Value
- Export for BI / ML use

## â­ 7. Airflow DAG
File: airflow_dags/retail_pipeline_dag.py
Pipeline tasks:
- Bronze ingestion
- Data validation
- Build Silver models
- Build Gold models
- Run PySpark segmentation
- Export CSVs for Power BI

## â­ 7. Business Insights (Sample Findings)
- Product Line R accounts for ~40% of total revenue
- Subcategory Helmets has the highest unit volume
- Customer segment â€œHigh Valueâ€ contributes over 55% of revenue
- Australia is the strongest region by total sales
- Revenue spikes during Novâ€“Jan (holiday period)
- Repeat customers generate 2.4Ã— more revenue than one-time buyers

## â­ 8. Conclusion
This project demonstrates real-world analytics engineering skills:
- Data ingestion
- Data modeling
- Orchestration
- KPI engineering
- Distributed processing
- BI reporting
- Medallion architecture
